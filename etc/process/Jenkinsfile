#!/usr/bin/env groovy
//
// The main Jenkinsfile for FIBO, defining the Build/Publish/Test/Deploy process that is
// executed for each push into the repository.
//
// Note that this file is in the so called "Declarative Pipeline" syntax
//
// See https://jenkins.io/doc/book/pipeline/jenkinsfile/
//
//String[] derivedProducts = ['widoco', 'fibopedia', 'glossary', 'vocabulary', 'datadictionary', 'reference']
String[] derivedProducts = ['widoco', 'fibopedia', 'glossary', 'vocabulary', 'datadictionary']
//String[] derivedProducts = ['widoco']

env.ONTPUB_FAMILY='fibo'
env.ONTPUB_SPEC_HOST='spec.edmcouncil.org'
env.ONTPUB_IS_DARK_MODE='1'
env.ONTPUB_IMAGE='edmcouncil/ontology-publisher:v0.1.0'
env.LC_ALL='en_US.UTF-8'
env.LANG='en_US.UTF-8'
env.LANGUAGE='en_US.UTF-8'
env.NGINX_SPEC_ROOT='/mnt/jenkins-disk/spec.edmcouncil.org'

properties([
  buildDiscarder(
          logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '', daysToKeepStr: '', numToKeepStr: '30')
  ),
  //
  // We let each stage running on each jenkins slave / agent decide what to check out or not
  //
//  skipDefaultCheckout(),
  //
  // Skip stages once the build status has gone to UNSTABLE.
  //
//  skipStagesAfterUnstable(),
  //
  // There must be SOME limit, if it hangs or whatever then that's a bug and therefore cancel the job.
  //
//  timeout(time: 23, unit: 'HOURS'),
  //
  // Prepend all console output generated by the Pipeline run with the time at which the line was emitted
  //
  //timestamps()
//  ansiColor('xterm')
])

node {
  ansiColor('xterm') {
    stage('Setup') {
      //
      // First load the library of vars/*.groovy files from the /etc/process/vars directory in the fibo repo.
      // Do this on the master itself, no need to run this in a docker container on a slave, it's a light weight
      // process.
      //
      node('master') { // load library
        try {
          dir('input/fibo') {
            checkout([
              $class                           : 'GitSCM',
              branches                         : scm.branches,
              doGenerateSubmoduleConfigurations: false,
              submoduleCfg                     : [],
              extensions                       : scm.extensions + [
                [$class: 'LocalBranch', localBranch: '**'],
                [$class: 'CheckoutOption', timeout: 1],
                [$class: 'IgnoreNotifyCommit'],
                [$class: 'WipeWorkspace'],
                [$class: 'SparseCheckoutPaths', sparseCheckoutPaths: [
                  [$class: 'SparseCheckoutPath', path: 'etc/process/']
                ]]
              ],
              userRemoteConfigs                : scm.userRemoteConfigs
            ])
          }
          def repoPath = 'input/fibo/etc/process'
          // create new git repo inside jenkins subdirectory
          dir(repoPath) {
            sh returnStdout: false, script: '''
              set +x
              rm -rf .git >/dev/null 2>&1 || true
              git init 
              git add --all .
              git config --local user.name "jenkins"
              git config --local user.email jenkins@edmcouncil.org
              git commit -m init || true
              git ls-tree -r master --name-only || true
            '''
            library(identifier: 'local-lib@master', retriever: modernSCM([$class: 'GitSCMSource', remote: "${env.WORKSPACE}/${repoPath}"])) _
          }
          initScript.isLoaded()
        } catch (e) {
          echo "Some error occurred during init stage: ${e}"
          throw e
        }
        echo "All good to go"
      }
    }

    publishScript.hygiene().call()

    publishScript.product('ontology').call()

    stage('Build Derived Products') {
      def parallelStages = derivedProducts.collectEntries { product ->
        [ "Build ${product}" : publishScript.product(product)]
      }
      parallel(parallelStages)
    }

    publishScript.publish(derivedProducts).call()

    //
    // Run the publish on the master jenkins agent by just copying all the generated artifacts right into the workspace
    // on master and let NGINX just serve it from there.
    //
    // This workspace will never be "wiped" so it contains all the older versions as well, wiping this workspace
    // will be bad because we would lose all previously published versions
    //
    stage('Publish') {
      node('master') {
        try {

          echo "Cleaning workspace:"
          sh 'rm -rf ${WORKSPACE}/* || true'
          echo "Done cleaning"

          sh 'test -d ${NGINX_SPEC_ROOT}'
          sh 'ls -al ${NGINX_SPEC_ROOT}/'
          sh 'pwd'

          dir('output') {
            echo 'Unstashing the output of the publish stage'
            unstash 'publishable-output'
            sh 'pwd && ls -al'

            echo "Copy all generated content to ${NGINX_SPEC_ROOT}:"
            sh '''
              cp -vr . ${NGINX_SPEC_ROOT}/ > ${WORKSPACE}/published-files.log 2>&1 || true
              rc=$?
              if ((rc == 0)); then
                echo "Successfully copied all files to destination, see published-files.log in the workspace"
              else
                echo "Some files may not have been copied"
                tail published-files.log
                exit 1
              fi
            '''
          }
          //
          // Archive all log files (including published-files.log) so that they can easily be viewed from the
          // Jenkins job page
          //
          archiveArtifacts artifacts: '**/*.log', allowEmptyArchive: true
          //
        } catch (e) {
          currentBuild.result = "FAILURE"
          echo "Failed the \"${STAGE_NAME}\" stage: ${e}"
          throw e
        } finally {
          slackScript.notifyStage()
        }
      } // end of node('master')
    } // end of stage "Publish"
  } // end of ansiColor('xterm')
}
