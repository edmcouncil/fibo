#!/usr/bin/env groovy
//
// The main Jenkinsfile for FIBO, defining the Build/Publish/Test/Deploy process that is
// executed for each push into the repository.
//
// Note that this file is in the so called "Declarative Pipeline" syntax
//
// See https://jenkins.io/doc/book/pipeline/jenkinsfile/
//
//String[] derivedProducts = ['widoco', 'fibopedia', 'glossary', 'vocabulary', 'datadictionary', 'reference']
String[] derivedProducts = ['widoco']

env.ONTPUB_FAMILY='fibo'
env.ONTPUB_SPEC_HOST='spec.edmcouncil.org'
env.ONTPUB_IS_DARK_MODE='1'
env.ONTPUB_IMAGE='edmcouncil/ontology-publisher:latest'
env.LC_ALL='en_US.UTF-8'
env.LANG='en_US.UTF-8'
env.LANGUAGE='en_US.UTF-8'
env.NGINX_SPEC_ROOT='/mnt/jenkins-disk/spec.edmcouncil.org'

properties([
  buildDiscarder(
          logRotator(artifactDaysToKeepStr: '', artifactNumToKeepStr: '', daysToKeepStr: '', numToKeepStr: '5')
  ),
  //
  // We let each stage running on each jenkins slave / agent decide what to check out or not
  //
//  skipDefaultCheckout(),
  //
  // Skip stages once the build status has gone to UNSTABLE.
  //
//  skipStagesAfterUnstable(),
  //
  // There must be SOME limit, if it hangs or whatever then that's a bug and therefore cancel the job.
  //
//  timeout(time: 23, unit: 'HOURS'),
  //
  // Prepend all console output generated by the Pipeline run with the time at which the line was emitted
  //
  //timestamps()
//  ansiColor('xterm')
])

node {
  ansiColor('xterm') {
    //
    // First load the library of vars/*.groovy files from the /etc/process/vars directory in the fibo repo.
    // Do this on the master itself, no need to run this in a docker container on a slave, it's a light weight
    // process.
    //
    node('master') { // load library
      try {
        dir('input/fibo') {
          checkout([
                  $class: 'GitSCM',
                  branches: scm.branches,
                  doGenerateSubmoduleConfigurations: false,
                  submoduleCfg: [],
                  extensions: scm.extensions + [
                          [$class: 'LocalBranch', localBranch: '**'],
                          [$class: 'CheckoutOption', timeout: 1],
                          [$class: 'IgnoreNotifyCommit'],
                          [$class: 'WipeWorkspace'],
                          [$class: 'SparseCheckoutPaths',  sparseCheckoutPaths: [
                                  [$class:'SparseCheckoutPath', path:'etc/process/']
                          ]]
                  ],
                  userRemoteConfigs: scm.userRemoteConfigs
          ])
        }
        def repoPath = 'input/fibo/etc/process'
        // create new git repo inside jenkins subdirectory
        dir(repoPath) {
          sh returnStdout: false, script: '''
            set +x
            rm -rf .git >/dev/null 2>&1 || true
            git init 
            git add --all .
            git config --local user.name "jenkins"
            git config --local user.email jenkins@edmcouncil.org
            git commit -m init || true
            git ls-tree -r master --name-only || true
          '''
          def repoPathFull = "${env.WORKSPACE}/${repoPath}"
          echo "repoPathFull=${repoPathFull}"
          library(identifier: 'local-lib@master', retriever: modernSCM([$class: 'GitSCMSource', remote: repoPathFull])) _
        }
        initScript.isLoaded()
      } catch(e) {
        echo "Some error occurred during init stage: ${e}"
        throw e
      }
      echo "All good to go"
    }

    publishScript.hygiene().call()

    publishScript.product('ontology').call()

    stage('Build Derived Products') {
      def parallelStages = derivedProducts.collectEntries { product ->
        [ "Build ${product}" : publishScript.product(product)]
      }
      parallel(parallelStages)
    }

    publishScript.publish().call()

    //
    // Run the publish on the master jenkins agent by just copying all the generated artifacts right into the workspace
    // on master and let NGINX just serve it from there.
    //
    // This workspace will never be "wiped" so it contains all the older versions as well, wiping this workspace
    // will be bad because we would lose all previously published versions
    //
    stage('Publish') {
      node('master') {
        try {

          echo "Cleaning workspace:"
          sh 'rm -rf .* * || true'
          echo "Done cleaning"

          sh 'test -d ${NGINX_SPEC_ROOT}'
          sh 'ls -al ${NGINX_SPEC_ROOT}/'
          sh 'pwd'

          echo 'Unstashing the output of the publish stage'

          dir('output') {
            unstash 'publishable-output'
            sh 'pwd && ls -al'

            echo "Copy all generated content to ${NGINX_SPEC_ROOT}:"
            sh '''
              cp -vr . ${NGINX_SPEC_ROOT}/ > published-files.log 2>&1 || true
              rc=$?
              if ((rc == 0)); then
                echo "Successfully copied all files to destination, see published-files.log in the workspace"
              else
                echo "Some files may not have been copied"
                tail published-files.log
                exit 1
              fi
            '''
          }

          //
        } catch (e) {
          currentBuild.result = "FAILURE"
          echo "Failed the \"${STAGE_NAME}\" stage: ${e}"
          pullRequestStatus("Publish stage failed")
          throw e
        } finally {
          slackScript.notifyStage()
          pullRequestStatus("Publish stage was successful")
        }
      } // end of node('master')
    } // end of stage "Publish"
  }
}
